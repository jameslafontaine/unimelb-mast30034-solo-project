{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landing Layer to Raw Layer (renaming columns, data type conversions, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/08/06 15:07:52 WARN Utils: Your hostname, DESKTOP-SATV84A resolves to a loopback address: 127.0.1.1; using 172.26.254.29 instead (on interface eth0)\n",
      "23/08/06 15:07:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/06 15:07:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/06 15:07:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\") # fix timestamps loaded by spark\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yellow Taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for raw layer\n",
    "\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "if not os.path.exists('../data/raw/'):\n",
    "    os.makedirs('../data/raw/')\n",
    "    \n",
    "if not os.path.exists('../data/raw/tlc'):\n",
    "    os.makedirs('../data/raw/tlc')\n",
    "    \n",
    "if not os.path.exists('../data/raw/tlc/yellow'):\n",
    "    os.makedirs('../data/raw/tlc/yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_landing_dir = '../data/landing/tlc/yellow/'\n",
    "\n",
    "sdf_yellow_2022_05 = spark.read.parquet(f\"{yellow_landing_dir}2022-05.parquet\")\n",
    "\n",
    "sdf_yellow_all = spark.read.parquet(f\"{yellow_landing_dir}*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('tpep_pickup_datetime', TimestampNTZType(), True), StructField('tpep_dropoff_datetime', TimestampNTZType(), True), StructField('passenger_count', DoubleType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', DoubleType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_yellow_2022_05.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('tpep_pickup_datetime', TimestampNTZType(), True), StructField('tpep_dropoff_datetime', TimestampNTZType(), True), StructField('passenger_count', DoubleType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', DoubleType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_yellow_all.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schemas appear to be incorrect for all of 2022, so we will adjust some data types and ensure consistent lowercase casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampNTZType(), True), StructField('tpep_dropoff_datetime', TimestampNTZType(), True), StructField('passenger_count', IntegerType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', IntegerType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('payment_type', IntegerType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# renaming\n",
    "sdf.withColumnRenamed(\n",
    "    'column_from',\n",
    "    'column_to'\n",
    ")\n",
    "\n",
    "# example 1 for converting data types\n",
    "sdf.withColumn(\n",
    "    'column_to',\n",
    "    F.col('column_from').cast('data type')\n",
    ")\n",
    "'''\n",
    "\n",
    "# convert data types\n",
    "\n",
    "sdf_yellow_2022_05 = sdf_yellow_2022_05.withColumn(\n",
    "    'VendorID', \n",
    "    F.col('VendorID').cast('Integer') \n",
    ")\n",
    "\n",
    "sdf_yellow_2022_05 = sdf_yellow_2022_05.withColumn(\n",
    "    'PULocationID', \n",
    "    F.col('PULocationID').cast('Integer') \n",
    ")\n",
    "\n",
    "sdf_yellow_2022_05 = sdf_yellow_2022_05.withColumn(\n",
    "    'DOLocationID', \n",
    "    F.col('DOLocationID').cast('Integer') \n",
    ")\n",
    "\n",
    "sdf_yellow_2022_05 = sdf_yellow_2022_05.withColumn(\n",
    "    'payment_type', \n",
    "    F.col('payment_type').cast('Integer') \n",
    ")\n",
    "\n",
    "sdf_yellow_2022_05 = sdf_yellow_2022_05.withColumn(\n",
    "    'RatecodeID', \n",
    "    F.col('RatecodeID').cast('Integer') \n",
    ")\n",
    "\n",
    "sdf_yellow_2022_05 = sdf_yellow_2022_05.withColumn(\n",
    "    'passenger_count',\n",
    "    F.col('passenger_count').cast('Integer')\n",
    ")\n",
    "\n",
    "\n",
    "sdf_yellow_2022_05.schema\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('vendorid', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampNTZType(), True), StructField('tpep_dropoff_datetime', TimestampNTZType(), True), StructField('passenger_count', IntegerType(), True), StructField('trip_distance', DoubleType(), True), StructField('ratecodeid', IntegerType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('pulocationid', IntegerType(), True), StructField('dolocationid', IntegerType(), True), StructField('payment_type', IntegerType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, we want to ensure everything has consistent casing to make our lives easier\n",
    "consistent_col_casing = [F.col(col_name).alias(col_name.lower()) for col_name in sdf_yellow_2022_05.columns]\n",
    "sdf_yellow_2022_05 = sdf_yellow_2022_05.select(*consistent_col_casing)\n",
    "\n",
    "# this will be used in the cell below when reading in\n",
    "sdf_schema = sdf_yellow_2022_05.schema\n",
    "sdf_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# convert all landing datasets to required schema\n",
    "\n",
    "yellow_landing_dir = '../data/landing/tlc/yellow/'\n",
    "    \n",
    "yellow_raw_dir = '../data/raw/tlc/yellow/'\n",
    "\n",
    "YEARS = ['2022']\n",
    "MONTHS = range(5,12)\n",
    "\n",
    "for year in YEARS:\n",
    "    for month in MONTHS:\n",
    "\n",
    "        month = str(month).zfill(2) \n",
    "\n",
    "        sdf_malformed = spark.read.parquet(f\"{yellow_landing_dir}{year}-{month}.parquet\")\n",
    "\n",
    "        # select all columns from the existing malformed dataframe and cast it to the required schema and change casing, drop ehail_fee as it has only NULL values\n",
    "        sdf_malformed = sdf_malformed \\\n",
    "            .select([F.col(c).cast(sdf_schema[i].dataType) for i, c in enumerate(sdf_malformed.columns)]) \\\n",
    "            .select(*consistent_col_casing) \\\n",
    "        \n",
    "        sdf_malformed \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet(f\"{yellow_raw_dir}{year}-{month}.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " vendorid              | 1                   \n",
      " tpep_pickup_datetime  | 2022-05-01 00:00:36 \n",
      " tpep_dropoff_datetime | 2022-05-01 00:19:18 \n",
      " passenger_count       | 1                   \n",
      " trip_distance         | 4.1                 \n",
      " ratecodeid            | 1                   \n",
      " store_and_fwd_flag    | N                   \n",
      " pulocationid          | 246                 \n",
      " dolocationid          | 151                 \n",
      " payment_type          | 2                   \n",
      " fare_amount           | 17.0                \n",
      " extra                 | 3.0                 \n",
      " mta_tax               | 0.5                 \n",
      " tip_amount            | 0.0                 \n",
      " tolls_amount          | 0.0                 \n",
      " improvement_surcharge | 0.3                 \n",
      " total_amount          | 20.8                \n",
      " congestion_surcharge  | 2.5                 \n",
      " airport_fee           | 0.0                 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" checkinglanding vs raw dataset shape and landing dataset shape of jan 2022\\nsdf2 = spark.read.parquet('../data/raw/tlc/yellow/2022')\\n\\nsdf2.show(1, vertical=True, truncate=100)\\n\\nprint(sdf1.count())\\n\\nprint(sdf2.count())\\n\\nsdf = spark.read.parquet('../data/raw/tlc/yellow/2022/2022-01.parquet')\\n\\nsdf.show(1, vertical=True, truncate=100)\\n\\nprint(sdf.count())\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check schema of raw layer data\n",
    "\n",
    "sdf1 = spark.read.parquet('../data/raw/tlc/yellow/*')\n",
    "\n",
    "sdf1.show(1, vertical=True, truncate=100)\n",
    "\n",
    "#sdf1.show(1, vertical=True, truncate=100)\n",
    "\n",
    "''' checkinglanding vs raw dataset shape and landing dataset shape of jan 2022\n",
    "sdf2 = spark.read.parquet('../data/raw/tlc/yellow/2022')\n",
    "\n",
    "sdf2.show(1, vertical=True, truncate=100)\n",
    "\n",
    "print(sdf1.count())\n",
    "\n",
    "print(sdf2.count())\n",
    "\n",
    "sdf = spark.read.parquet('../data/raw/tlc/yellow/2022/2022-01.parquet')\n",
    "\n",
    "sdf.show(1, vertical=True, truncate=100)\n",
    "\n",
    "print(sdf.count())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for raw layer\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "if not os.path.exists('../data/raw/'):\n",
    "    os.makedirs('../data/raw/')\n",
    "    \n",
    "if not os.path.exists('../data/raw/tlc'):\n",
    "    os.makedirs('../data/raw/tlc')\n",
    "    \n",
    "if not os.path.exists('../data/raw/tlc/taxi_zones'):\n",
    "    os.makedirs('../data/raw/tlc/taxi_zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_lookup = spark.read.option(\"header\",True) \\\n",
    "                   .csv(\"../data/landing/tlc/taxi_zones/taxi+_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "\n",
      "StructType([StructField('LocationID', StringType(), True), StructField('Borough', StringType(), True), StructField('Zone', StringType(), True), StructField('service_zone', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "print(taxi_zone_lookup.limit(5))\n",
    "\n",
    "print(taxi_zone_lookup.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just need to convert the column names to lowercase for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|locationid|      borough|                zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "\n",
      "StructType([StructField('locationid', StringType(), True), StructField('borough', StringType(), True), StructField('zone', StringType(), True), StructField('service_zone', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# converting to lower case\n",
    "consistent_col_casing = [F.col(col_name).alias(col_name.lower()) for col_name in taxi_zone_lookup.columns]\n",
    "taxi_zone_lookup = taxi_zone_lookup.select(*consistent_col_casing)\n",
    "\n",
    "\n",
    "\n",
    "print(taxi_zone_lookup.limit(5))\n",
    "print(taxi_zone_lookup.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw layer data as parquet\n",
    "taxi_zone_lookup \\\n",
    "    .coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet('../data/raw/tlc/taxi_zones/taxi_zone_lookup.parquet')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of +----------+-------------+--------------------+------------+\n",
       "|locationid|      borough|                zone|service_zone|\n",
       "+----------+-------------+--------------------+------------+\n",
       "|         1|          EWR|      Newark Airport|         EWR|\n",
       "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
       "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
       "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
       "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
       "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
       "|         7|       Queens|             Astoria|   Boro Zone|\n",
       "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
       "|         9|       Queens|          Auburndale|   Boro Zone|\n",
       "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
       "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
       "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
       "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
       "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
       "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
       "|        16|       Queens|             Bayside|   Boro Zone|\n",
       "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
       "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
       "|        19|       Queens|           Bellerose|   Boro Zone|\n",
       "|        20|        Bronx|             Belmont|   Boro Zone|\n",
       "+----------+-------------+--------------------+------------+\n",
       "only showing top 20 rows\n",
       ">"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check raw layer data\n",
    "taxi_zone_lookup = spark.read.parquet('../data/raw/tlc/taxi_zones/taxi_zone_lookup.parquet')\n",
    "\n",
    "taxi_zone_lookup.printSchema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move taxi_zones.zip to raw layer data\n",
    "import shutil\n",
    "\n",
    "src = '../data/landing/tlc/taxi_zones/taxi_zones.zip'\n",
    "\n",
    "dst = '../data/raw/tlc/taxi_zones/taxi_zones.zip'\n",
    "\n",
    "shutil.copyfile(src, dst)\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# unzip shapefile\n",
    "with zipfile.ZipFile(dst, 'r') as zip_ref:\n",
    "    zip_ref.extractall('../data/raw/tlc/taxi_zones')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subway Entrances and Exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for raw layer\n",
    "\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "if not os.path.exists('../data/raw/'):\n",
    "    os.makedirs('../data/raw/')\n",
    "    \n",
    "if not os.path.exists('../data/raw/subway_entr_exit'):\n",
    "    os.makedirs('../data/raw/subway_entr_exit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+--------------------+\n",
      "|division|            line|    station_location|\n",
      "+--------+----------------+--------------------+\n",
      "|     IRT|        Flushing|(40.755882, -74.0...|\n",
      "|     IND|        8 Avenue|(40.740893, -74.0...|\n",
      "|     BMT|        Canarsie|(40.739777, -74.0...|\n",
      "|     IRT|Broadway-7th Ave|(40.737826, -74.0...|\n",
      "|     IRT|Broadway-7th Ave|(40.733422, -74.0...|\n",
      "+--------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subway_entr_exit = spark.read.parquet('../data/landing/subway_entr_exit/subway_entr_exit.parquet')\n",
    "\n",
    "subway_entr_exit.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove division and line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_entr_exit = subway_entr_exit.select('station_location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_entr_exit \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('../data/raw/subway_entr_exit/subway_entr_exit.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hotel Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for raw layer\n",
    "\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "if not os.path.exists('../data/raw/'):\n",
    "    os.makedirs('../data/raw/')\n",
    "    \n",
    "if not os.path.exists('../data/raw/hotels'):\n",
    "    os.makedirs('../data/raw/hotels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----+----+-------+-------------+----------------+--------+----------+--------+--------------------+---------+---------+----------+---------------+----------------+------------+---------+-------------+--------------------+\n",
      "|     PARID|BOROCODE|BLOCK| LOT|TAXYEAR|STREET NUMBER|     STREET NAME|Postcode|BLDG_CLASS|TAXCLASS|          OWNER_NAME|  Borough| Latitude| Longitude|Community Board|Council District|Census Tract|      BIN|          BBL|                 NTA|\n",
      "+----------+--------+-----+----+-------+-------------+----------------+--------+----------+--------+--------------------+---------+---------+----------+---------------+----------------+------------+---------+-------------+--------------------+\n",
      "|1000080039|       1|    8|  39|   2021|           32|    PEARL STREET|   10004|        H3|       4|       32 PEARL, LLC|MANHATTAN|40.703235|-74.012421|          101.0|             1.0|         9.0|1078968.0|1.000080039E9|Battery Park City...|\n",
      "|1000080051|       1|    8|  51|   2021|            6|    WATER STREET|   10004|        H2|       4|           AI IV LLC|MANHATTAN|40.702744|-74.012201|          101.0|             1.0|         9.0|1090472.0|1.000080051E9|Battery Park City...|\n",
      "|1000100033|       1|   10|  33|   2021|            8|    STONE STREET|   10004|        H2|       4|B.H. 8 STONE STRE...|MANHATTAN|40.704025|-74.012638|          101.0|             1.0|         9.0|1087618.0|1.000100033E9|Battery Park City...|\n",
      "|1000110029|       1|   11|  29|   2021|           11|    STONE STREET|   10004|        H2|       4|PREMIER EMERALD, LLC|MANHATTAN|40.704039|-74.012317|          101.0|             1.0|         9.0|1000041.0|1.000110029E9|Battery Park City...|\n",
      "|1000161301|       1|   16|1301|   2021|          102|NORTH END AVENUE|   10282|        RH|       4|       GOLDMAN SACHS|MANHATTAN|40.714812|-74.016153|          101.0|             1.0|     31703.0|1085867.0|1.000167512E9|Battery Park City...|\n",
      "+----------+--------+-----+----+-------+-------------+----------------+--------+----------+--------+--------------------+---------+---------+----------+---------------+----------------+------------+---------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hotels = spark.read.parquet('../data/landing/hotels/hotels.parquet')\n",
    "\n",
    "hotels.schema\n",
    "\n",
    "hotels.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to lowercase, remove useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+----------+\n",
      "|taxyear|  borough| latitude| longitude|\n",
      "+-------+---------+---------+----------+\n",
      "|   2021|MANHATTAN|40.703235|-74.012421|\n",
      "|   2021|MANHATTAN|40.702744|-74.012201|\n",
      "|   2021|MANHATTAN|40.704025|-74.012638|\n",
      "|   2021|MANHATTAN|40.704039|-74.012317|\n",
      "|   2021|MANHATTAN|40.714812|-74.016153|\n",
      "+-------+---------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hotels = hotels.select('TAXYEAR', 'Borough', 'Latitude', 'Longitude')\n",
    "\n",
    "# consistent lowercasing and underscores where there are spaces\n",
    "consistent_col_casing = [F.col(col_name).alias(col_name.lower().replace(\" \", \"_\")) for col_name in hotels.columns]\n",
    "hotels = hotels.select(*consistent_col_casing)\n",
    "\n",
    "hotels.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('../data/raw/hotels/hotels.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for raw layer\n",
    "\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "if not os.path.exists('../data/raw/'):\n",
    "    os.makedirs('../data/raw/')\n",
    "    \n",
    "if not os.path.exists('../data/raw/airbnb'):\n",
    "    os.makedirs('../data/raw/airbnb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------+---------+-------------------+------------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-------+\n",
      "|  id|                name|host_id|host_name|neighbourhood_group|     neighbourhood|latitude|longitude|      room_type|price|minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|number_of_reviews_ltm|license|\n",
      "+----+--------------------+-------+---------+-------------------+------------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-------+\n",
      "|5136|Spacious Brooklyn...|   7378|  Rebecca|           Brooklyn|       Sunset Park|40.66265|-73.99454|Entire home/apt|  275|            21|                3| 2022-08-10|             0.03|                             1|             267|                    1|   null|\n",
      "|5203|Cozy Clean Guest ...|   7490|MaryEllen|          Manhattan|   Upper West Side| 40.8038|-73.96751|   Private room|   75|             2|              118| 2017-07-21|             0.73|                             1|               0|                    0|   null|\n",
      "|5121|     BlissArtsSpace!|   7356|    Garon|           Brooklyn|Bedford-Stuyvesant|40.68535|-73.95512|   Private room|   60|            30|               50| 2019-12-02|              0.3|                             2|             322|                    0|   null|\n",
      "|5178|Large Furnished R...|   8967| Shunichi|          Manhattan|           Midtown|40.76457|-73.98317|   Private room|   68|             2|              559| 2022-11-20|             3.38|                             1|              79|                   50|   null|\n",
      "|2595|Skylit Midtown Ca...|   2845| Jennifer|          Manhattan|           Midtown|40.75356|-73.98559|Entire home/apt|  175|            30|               49| 2022-06-21|             0.31|                             3|             365|                    1|   null|\n",
      "+----+--------------------+-------+---------+-------------------+------------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airbnb = spark.read.parquet('../data/landing/airbnb/airbnb.parquet')\n",
    "\n",
    "airbnb.schema\n",
    "\n",
    "airbnb.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to lowercase, remove useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+---------+---------------+-----+--------------+-----------------+\n",
      "|neighbourhood_group|latitude|longitude|      room_type|price|minimum_nights|reviews_per_month|\n",
      "+-------------------+--------+---------+---------------+-----+--------------+-----------------+\n",
      "|           Brooklyn|40.66265|-73.99454|Entire home/apt|  275|            21|             0.03|\n",
      "|          Manhattan| 40.8038|-73.96751|   Private room|   75|             2|             0.73|\n",
      "|           Brooklyn|40.68535|-73.95512|   Private room|   60|            30|              0.3|\n",
      "|          Manhattan|40.76457|-73.98317|   Private room|   68|             2|             3.38|\n",
      "|          Manhattan|40.75356|-73.98559|Entire home/apt|  175|            30|             0.31|\n",
      "+-------------------+--------+---------+---------------+-----+--------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airbnb = airbnb.select('neighbourhood_group', 'latitude', 'longitude', 'room_type', 'price', 'minimum_nights', 'reviews_per_month')\n",
    "\n",
    "# consistent lowercasing and underscores where there are spaces\n",
    "consistent_col_casing = [F.col(col_name).alias(col_name.lower().replace(\" \", \"_\")) for col_name in airbnb.columns]\n",
    "airbnb = airbnb.select(*consistent_col_casing)\n",
    "\n",
    "airbnb.show(5)\n",
    "\n",
    "airbnb = airbnb.withColumnRenamed(\n",
    "    'price',\n",
    "    'daily_price_usd'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('../data/raw/airbnb/airbnb.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for raw layer\n",
    "\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "if not os.path.exists('../data/raw/'):\n",
    "    os.makedirs('../data/raw/')\n",
    "    \n",
    "if not os.path.exists('../data/raw/census'):\n",
    "    os.makedirs('../data/raw/census')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-------+--------+----+-----+--------+-----+-----+------+-----+-------+-------+---------+------------+---------------+-------+------------+------------+-------+------+------------+----------+-----+-------+-------+----+-----------+----------+-----------+--------+-----------+----------+------------+----------+------------+\n",
      "|CensusTract|County|Borough|TotalPop| Men|Women|Hispanic|White|Black|Native|Asian|Citizen| Income|IncomeErr|IncomePerCap|IncomePerCapErr|Poverty|ChildPoverty|Professional|Service|Office|Construction|Production|Drive|Carpool|Transit|Walk|OtherTransp|WorkAtHome|MeanCommute|Employed|PrivateWork|PublicWork|SelfEmployed|FamilyWork|Unemployment|\n",
      "+-----------+------+-------+--------+----+-----+--------+-----+-----+------+-----+-------+-------+---------+------------+---------------+-------+------------+------------+-------+------+------------+----------+-----+-------+-------+----+-----------+----------+-----------+--------+-----------+----------+------------+----------+------------+\n",
      "|36005000100| Bronx|  Bronx|    7703|7133|  570|    29.9|  6.1| 60.9|   0.2|  1.6|   6476|   null|     null|      2440.0|          373.0|   null|        null|        null|   null|  null|        null|      null| null|   null|   null|null|       null|      null|       null|       0|       null|      null|        null|      null|        null|\n",
      "|36005000200| Bronx|  Bronx|    5403|2659| 2744|    75.8|  2.3| 16.0|   0.0|  4.2|   3639|72034.0|  13991.0|     22180.0|         2206.0|   20.0|        20.7|        28.7|   17.1|  23.9|         8.0|      22.3| 44.8|   13.7|   38.6| 2.9|        0.0|       0.0|       43.0|    2308|       80.8|      16.2|         2.9|       0.0|         7.7|\n",
      "|36005000400| Bronx|  Bronx|    5915|2896| 3019|    62.7|  3.6| 30.7|   0.0|  0.3|   4100|74836.0|   8407.0|     27700.0|         2449.0|   13.2|        23.6|        32.2|   23.4|  24.9|         9.0|      10.5| 41.3|   10.0|   44.6| 1.4|        0.5|       2.1|       45.0|    2675|       71.7|      25.3|         2.5|       0.6|         9.5|\n",
      "|36005001600| Bronx|  Bronx|    5879|2558| 3321|    65.1|  1.6| 32.4|   0.0|  0.0|   3536|32312.0|   6859.0|     17526.0|         2945.0|   26.3|        35.9|        19.1|   36.1|  26.2|         4.9|      13.8| 37.2|    5.3|   45.5| 8.6|        1.6|       1.7|       38.8|    2120|       75.0|      21.3|         3.8|       0.0|         8.7|\n",
      "|36005001900| Bronx|  Bronx|    2591|1206| 1385|    55.4|  9.0| 29.0|   0.0|  2.1|   1557|37936.0|   3771.0|     17986.0|         2692.0|   37.1|        31.5|        35.4|   20.9|  26.2|         6.6|      11.0| 19.2|    5.3|   63.9| 3.0|        2.4|       6.2|       45.4|    1083|       76.8|      15.5|         7.7|       0.0|        19.2|\n",
      "+-----------+------+-------+--------+----+-----+--------+-----+-----+------+-----+-------+-------+---------+------------+---------------+-------+------------+------------+-------+------+------------+----------+-----+-------+-------+----+-----------+----------+-----------+--------+-----------+----------+------------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "census_tracts = spark.read.parquet('../data/landing/census/census_tracts.parquet')\n",
    "\n",
    "census_tracts.schema\n",
    "\n",
    "census_tracts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+---------------+---------+-----+\n",
      "|Latitude|     Longitude|      BlockCode|   County|State|\n",
      "+--------+--------------+---------------+---------+-----+\n",
      "|   40.48|        -74.28|340230076002012|Middlesex|   NJ|\n",
      "|   40.48|-74.2768341709|340230076005000|Middlesex|   NJ|\n",
      "|   40.48|-74.2736683417|340230076003018|Middlesex|   NJ|\n",
      "|   40.48|-74.2705025126|340230076003004|Middlesex|   NJ|\n",
      "|   40.48|-74.2673366834|340230074021000|Middlesex|   NJ|\n",
      "+--------+--------------+---------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "census_block_loc = spark.read.parquet('../data/landing/census/census_block_loc.parquet')\n",
    "\n",
    "census_block_loc.schema\n",
    "\n",
    "census_block_loc.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to lowercase, remove useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------+------------+-------+------------+-------+------+------------+----------+-----+-------+-------+----+----------+-----------+-----------+----------+------------+------------+\n",
      "|censustract|borough|totalpop|incomepercap|poverty|professional|service|office|construction|production|drive|carpool|transit|walk|workathome|meancommute|privatework|publicwork|selfemployed|unemployment|\n",
      "+-----------+-------+--------+------------+-------+------------+-------+------+------------+----------+-----+-------+-------+----+----------+-----------+-----------+----------+------------+------------+\n",
      "|36005000100|  Bronx|    7703|      2440.0|   null|        null|   null|  null|        null|      null| null|   null|   null|null|      null|       null|       null|      null|        null|        null|\n",
      "|36005000200|  Bronx|    5403|     22180.0|   20.0|        28.7|   17.1|  23.9|         8.0|      22.3| 44.8|   13.7|   38.6| 2.9|       0.0|       43.0|       80.8|      16.2|         2.9|         7.7|\n",
      "|36005000400|  Bronx|    5915|     27700.0|   13.2|        32.2|   23.4|  24.9|         9.0|      10.5| 41.3|   10.0|   44.6| 1.4|       2.1|       45.0|       71.7|      25.3|         2.5|         9.5|\n",
      "|36005001600|  Bronx|    5879|     17526.0|   26.3|        19.1|   36.1|  26.2|         4.9|      13.8| 37.2|    5.3|   45.5| 8.6|       1.7|       38.8|       75.0|      21.3|         3.8|         8.7|\n",
      "|36005001900|  Bronx|    2591|     17986.0|   37.1|        35.4|   20.9|  26.2|         6.6|      11.0| 19.2|    5.3|   63.9| 3.0|       6.2|       45.4|       76.8|      15.5|         7.7|        19.2|\n",
      "+-----------+-------+--------+------------+-------+------------+-------+------+------------+----------+-----+-------+-------+----+----------+-----------+-----------+----------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "census_tracts = census_tracts.drop('County', 'income',  'incomeerr', 'incomepercaperr', 'childpoverty', 'men', 'women', 'hispanic', 'black', 'white', 'native', 'asian', 'citizen', 'employed', 'othertransp', 'familywork')\n",
    "\n",
    "# consistent lowercasing and underscores where there are spaces\n",
    "consistent_col_casing = [F.col(col_name).alias(col_name.lower().replace(\" \", \"_\")) for col_name in census_tracts.columns]\n",
    "census_tracts = census_tracts.select(*consistent_col_casing)\n",
    "\n",
    "census_tracts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+---------------+\n",
      "|latitude|     longitude|      blockcode|\n",
      "+--------+--------------+---------------+\n",
      "|   40.48|        -74.28|340230076002012|\n",
      "|   40.48|-74.2768341709|340230076005000|\n",
      "|   40.48|-74.2736683417|340230076003018|\n",
      "|   40.48|-74.2705025126|340230076003004|\n",
      "|   40.48|-74.2673366834|340230074021000|\n",
      "+--------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "census_block_loc = census_block_loc.select('latitude', 'longitude', 'blockcode')\n",
    "\n",
    "# consistent lowercasing and underscores where there are spaces\n",
    "consistent_col_casing = [F.col(col_name).alias(col_name.lower().replace(\" \", \"_\")) for col_name in census_block_loc.columns]\n",
    "census_block_loc = census_block_loc.select(*consistent_col_casing)\n",
    "\n",
    "census_block_loc.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_tracts \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('../data/raw/census/census_tracts.parquet')\n",
    "        \n",
    "census_block_loc \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('../data/raw/census/census_block_loc.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parking Munimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for raw layer\n",
    "\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "if not os.path.exists('../data/raw/'):\n",
    "    os.makedirs('../data/raw/')\n",
    "    \n",
    "if not os.path.exists('../data/raw/parking'):\n",
    "    os.makedirs('../data/raw/parking')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------+------------------+--------------------+---------------------+---------+---------+-----------------+--------------+--------------------+----------------+----------------+-----------------+----------------+----------------+--------------------+\n",
      "|ObjectID|Meter Number|Status|Pay By Cell Number|         Meter_Hours|Parking_Facility_Name| Facility|  Borough|        On_Street|Side_of_Street|         From_Street|       To_Street|        Latitude|        Longitude|               X|               Y|            Location|\n",
      "+--------+------------+------+------------------+--------------------+---------------------+---------+---------+-----------------+--------------+--------------------+----------------+----------------+-----------------+----------------+----------------+--------------------+\n",
      "|   11750|     1083076|Active|            113091|2HR Pas Mon-Sat 0...|                 null|On Street|Manhattan|   West 85 Street|             N|    Amsterdam Avenue|        Broadway|40.7875051180999|-73.9765950135923|990731.235713214|226187.112964138|POINT (-73.976595...|\n",
      "|    9857|     1443404|Active|            106172|3HR Com Mon-Fri 0...|                 null|On Street|Manhattan|   West 30 Street|             N|            Broadway|        5 Avenue|40.7461997160805|-73.9869404709221|987868.647606388|211137.590897888|POINT (-73.986940...|\n",
      "|   11780|     1193006|Active|            113823|3HR Com Mon-Fri 0...|                 null|On Street|Manhattan| Lexington Avenue|             W|      East 85 Street|  East 84 Street|40.7784865293823|-73.9564275260737| 996317.58740139| 222903.46992515|POINT (-73.956427...|\n",
      "|    1111|     4512493|Active|            427918|6HR Pas Mon-Fri 0...|                 null|On Street|   Queens|Kissena Boulevard|             W|Horace Harding Ex...|Melbourne Avenue|40.7354393855834|-73.8148380161902|1035564.53745064|207271.225271061|POINT (-73.814838...|\n",
      "|   10122|     1443694|Active|            106557|2HR Pas Mon-Sat 0...|                 null|On Street|Manhattan|         3 Avenue|             W|      East 24 Street|  East 25 Street|40.7399045161829|-73.9825104553208|989096.612670138|208844.263135478|POINT (-73.982510...|\n",
      "+--------+------------+------+------------------+--------------------+---------------------+---------+---------+-----------------+--------------+--------------------+----------------+----------------+-----------------+----------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parking = spark.read.parquet('../data/landing/parking/parking.parquet')\n",
    "\n",
    "parking.schema\n",
    "\n",
    "parking.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to lowercase, remove useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------------+-----------------+\n",
      "|status|  borough|        latitude|        longitude|\n",
      "+------+---------+----------------+-----------------+\n",
      "|Active|Manhattan|40.7875051180999|-73.9765950135923|\n",
      "|Active|Manhattan|40.7461997160805|-73.9869404709221|\n",
      "|Active|Manhattan|40.7784865293823|-73.9564275260737|\n",
      "|Active|   Queens|40.7354393855834|-73.8148380161902|\n",
      "|Active|Manhattan|40.7399045161829|-73.9825104553208|\n",
      "+------+---------+----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parking = parking.select('status', 'borough', 'latitude', 'longitude')\n",
    "\n",
    "# consistent lowercasing and underscores where there are spaces\n",
    "consistent_col_casing = [F.col(col_name).alias(col_name.lower().replace(\" \", \"_\")) for col_name in parking.columns]\n",
    "parking = parking.select(*consistent_col_casing)\n",
    "\n",
    "parking.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('../data/raw/parking/parking.parquet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
