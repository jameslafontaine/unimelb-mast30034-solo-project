{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Layer to Curated Layer (filter and transform using business logic, feature engineering, aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/08/01 20:52:05 WARN Utils: Your hostname, DESKTOP-SATV84A resolves to a loopback address: 127.0.1.1; using 172.26.254.29 instead (on interface eth0)\n",
      "23/08/01 20:52:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/01 20:52:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\") # fix timestamps loaded by spark\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yellow Taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for curated data\n",
    "\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "if not os.path.exists('../data/curated/'):\n",
    "    os.makedirs('../data/curated/')\n",
    "    \n",
    "if not os.path.exists('../data/curated/tlc'):\n",
    "    os.makedirs('../data/curated/tlc')\n",
    "    \n",
    "if not os.path.exists('../data/curated/tlc/yellow'):\n",
    "    os.makedirs('../data/curated/tlc/yellow')\n",
    "    \n",
    "if not os.path.exists('../data/curated/tlc/yellow/2021'):\n",
    "    os.makedirs('../data/curated/tlc/yellow/2021')   \n",
    "    \n",
    "if not os.path.exists('../data/curated/tlc/yellow/2022'):\n",
    "    os.makedirs('../data/curated/tlc/yellow/2022')\n",
    "    \n",
    "if not os.path.exists('../data/curated/tlc/yellow/2023'):\n",
    "    os.makedirs('../data/curated/tlc/yellow/2023')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "yellow_raw_dir = '../data/raw/tlc/yellow/'\n",
    "\n",
    "yellow_curated_dir = '../data/curated/tlc/yellow/'\n",
    "\n",
    "sdf_yellow_2022_01 = spark.read.parquet(f\"{yellow_raw_dir}2022/2022-01.parquet\")\n",
    "\n",
    "sdf_yellow_2022_all = spark.read.parquet(f\"{yellow_raw_dir}2022/*\")\n",
    "\n",
    "sdf_yellow_2023_01 = spark.read.parquet(f\"{yellow_raw_dir}2023/2023-01.parquet\")\n",
    "\n",
    "sdf_yellow_2023_02 = spark.read.parquet(f\"{yellow_raw_dir}2023/2023-02.parquet\")\n",
    "\n",
    "#sdf_yellow_2022_all = spark.read.parquet('../data/cleaned/yellow/2022')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('vendorid', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampNTZType(), True), StructField('tpep_dropoff_datetime', TimestampNTZType(), True), StructField('passenger_count', IntegerType(), True), StructField('trip_distance', DoubleType(), True), StructField('ratecodeid', IntegerType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('pulocationid', IntegerType(), True), StructField('dolocationid', IntegerType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True)])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_yellow_2022_01.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392428\n",
      "2463931\n"
     ]
    }
   ],
   "source": [
    "sdf_yellow_2022_01.where(\n",
    "    (F.col('airport_fee') == 0)\n",
    "    & (F.col('pulocationid') != 132)\n",
    "    & (F.col('pulocationid') != 138)\n",
    "    | (F.col('pulocationid') == 132)\n",
    "    & (F.col('airport_fee') == 1.25)\n",
    "    | (F.col('pulocationid') == 138)\n",
    "    & (F.col('airport_fee') == 1.25)\n",
    "    ).where(\n",
    "        (F.col('airport_fee') != 1.25)\n",
    "        & (F.col('pulocationid') == 132)\n",
    "        & (F.col('pulocationid') == 138)\n",
    "        )\n",
    "\n",
    "'''\n",
    "sdf_yellow_2022_01.withColumn(\n",
    "    'is_valid_record',\n",
    "    # when we have a positive distance/passenger/total amount then True\n",
    "    # else False\n",
    "    F.when(\n",
    "        (F.col('airport_fee') == 0)\n",
    "        & (F.col('pulocationid') != 132)\n",
    "        & (F.col('pulocationid') != 138)\n",
    "        | (F.col('pulocationid') == 132)\n",
    "        & (F.col('airport_fee') == 1.25)\n",
    "        | (F.col('pulocationid') == 138)\n",
    "        & (F.col('airport_fee') == 1.25),\n",
    "        True\n",
    "    ).otherwise(False)\n",
    ").where(F.col('airport_fee') == 1.25)\n",
    "'''\n",
    "sdf_yellow_2022_01.where(\n",
    "    (F.col('vendorid') == 1)\n",
    "    | (F.col('vendorid') == 2)\n",
    "    ).where(\n",
    "        (F.col('vendorid') == 1)\n",
    "        & (F.col('vendorid') != 2)\n",
    ")\n",
    "    \n",
    "sdf_yellow_2022_01.where(\n",
    "    (F.col('extra') == 0.50) # ensure extra charges only applied for rush hour and overnight trips\n",
    "    & (F.hour('tpep_pickup_datetime') >= 20)\n",
    "    & (F.hour('tpep_pickup_datetime') < 6)\n",
    "    | (F.col('extra') == 0.50) #\n",
    "    & (F.hour('tpep_dropoff_datetime') >= 20)\n",
    "    & (F.hour('tpep_dropoff_datetime') < 6)\n",
    "    | (F.col('extra') == 1.00)\n",
    "    & (F.hour('tpep_pickup_datetime') >= 16)\n",
    "    & (F.hour('tpep_pickup_datetime') < 20)\n",
    "    | (F.col('extra') == 1.00) \n",
    "    & (F.hour('tpep_dropoff_datetime') >= 16)\n",
    "    & (F.hour('tpep_dropoff_datetime') < 20)\n",
    "    | (F.col('extra') == 0) \n",
    "    & (F.hour('tpep_pickup_datetime') >= 6)\n",
    "    & (F.hour('tpep_pickup_datetime') < 16)\n",
    "    & (F.hour('tpep_dropoff_datetime') >= 6)\n",
    "    & (F.hour('tpep_dropoff_datetime') < 16)\n",
    ").where(\n",
    "    (F.col('extra') != 0)\n",
    "    & (F.col('extra') != 1.0)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sdf_yellow_2022_01.where(\n",
    "        (F.col('extra') == 1.00) # ensure rush hour surcharge only applied for trips during rush hour\n",
    "        & (F.hour('tpep_pickup_datetime') >= 16)\n",
    "        & (F.hour('tpep_pickup_datetime') < 20)\n",
    "        | (F.col('extra') == 1.00) \n",
    "        & (F.hour('tpep_dropoff_datetime') >= 16)\n",
    "        & (F.hour('tpep_dropoff_datetime') < 20)\n",
    "        | (F.col('extra') == 0) \n",
    "        & (F.hour('tpep_pickup_datetime') >= 6)\n",
    "        & (F.hour('tpep_pickup_datetime') < 16)\n",
    "        & (F.hour('tpep_dropoff_datetime') >= 6)\n",
    "        & (F.hour('tpep_dropoff_datetime') < 16)\n",
    "        | (F.col('extra') == 0.50)\n",
    "        & (F.hour('tpep_pickup_datetime') >= 20)\n",
    "        | (F.col('extra') == 0.50) \n",
    "        & (F.hour('tpep_pickup_datetime') >= 20)\n",
    "        | (F.hour('tpep_pickup_datetime') < 6)\n",
    "        | (F.col('extra') == 0.50)\n",
    "        & (F.hour('tpep_pickup_datetime') >= 20)\n",
    "        | (F.hour('tpep_dropoff_datetime') < 6)\n",
    "    ).where(\n",
    "        (F.col('extra') == 0.5)\n",
    "        & (F.hour('tpep_pickup_datetime') >= 20)\n",
    "        & (F.dayofmonth('tpep_pickup_datetime') == 2)\n",
    "    )\n",
    "    \n",
    "print(sdf_yellow_2022_01.dropna('any').count())\n",
    "\n",
    "print(sdf_yellow_2022_01.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_zones = spark.read.parquet('../data/raw/tlc/taxi_zones/taxi_zone_lookup.parquet/')\n",
    "\n",
    "jfk_id = int(taxi_zones.where(\n",
    "    F.col('zone') == 'JFK Airport'\n",
    ").select('locationid').first()['locationid'])\n",
    "\n",
    "laguardia_id = int(taxi_zones.where(\n",
    "    F.col('zone') == 'LaGuardia Airport'\n",
    ").select('locationid').first()['locationid'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use business logic to filter and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m sdf_cleaned \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mparquet(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00myellow_cleaned_dir\u001b[39m}\u001b[39;00m\u001b[39m2022/2022-\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(month)\u001b[39m.\u001b[39mzfill(\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.parquet\u001b[39m\u001b[39m\"\u001b[39m)  \n\u001b[1;32m     11\u001b[0m \u001b[39m# remove invalid records by applying business logic\u001b[39;00m\n\u001b[1;32m     12\u001b[0m sdf_cleaned \u001b[39m=\u001b[39m \\\n\u001b[1;32m     13\u001b[0m sdf_cleaned\u001b[39m.\u001b[39mwhere(\n\u001b[0;32m---> 14\u001b[0m     (F\u001b[39m.\u001b[39;49myear(F\u001b[39m.\u001b[39;49mcol(\u001b[39m'\u001b[39;49m\u001b[39mtpep_pickup_datetime\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39m==\u001b[39;49m year) \u001b[39m# ensure that this trip was initiated within the correct year (assuming a trip belongs to a month based on pickup time)\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m     (F\u001b[39m.\u001b[39;49mmonth(F\u001b[39m.\u001b[39;49mcol(\u001b[39m'\u001b[39;49m\u001b[39mtpep_pickup_datetime\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39m==\u001b[39;49m month)  \u001b[39m# ensure that this trip was initiated within the correct month (assuming a trip belongs to a month based on pickup time)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39munix_timestamp(\u001b[39m'\u001b[39m\u001b[39mtpep_pickup_datetime\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m<\u001b[39m F\u001b[39m.\u001b[39munix_timestamp(\u001b[39m'\u001b[39m\u001b[39mtpep_dropoff_datetime\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m# make sure pickup time is earlier than dropoff time\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mpassenger_count\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m# ensure non-zero passenger count, trip distance and total amount\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtrip_distance\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n\u001b[1;32m     20\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n\u001b[1;32m     21\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n\u001b[1;32m     22\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n\u001b[1;32m     23\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n\u001b[1;32m     24\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n\u001b[1;32m     25\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mpayment_type\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m# include only credit card payments as cash tips are not included\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39msum\u001b[39m(sdf_yellow_2022_01[col] \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m payment_cols)) \u001b[39m# check the total amount equals the sum of all other fees\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \n\u001b[1;32m     28\u001b[0m )\u001b[39m.\u001b[39mwithColumn(\n\u001b[1;32m     29\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mstore_and_fwd_flag\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     30\u001b[0m     (F\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mstore_and_fwd_flag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mcast(\u001b[39m'\u001b[39m\u001b[39mBOOLEAN\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m sdf_cleaned \u001b[39m=\u001b[39m sdf_cleaned\u001b[39m.\u001b[39mwithColumn(\n\u001b[1;32m     34\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mstore_and_fwd_flag\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m     (F\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mstore_and_fwd_flag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mcast(\u001b[39m'\u001b[39m\u001b[39mBOOLEAN\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     44\u001b[0m sdf_cleaned \\\n\u001b[1;32m     45\u001b[0m \u001b[39m.\u001b[39mcoalesce(\u001b[39m1\u001b[39m) \\\n\u001b[1;32m     46\u001b[0m \u001b[39m.\u001b[39mwrite \\\n\u001b[1;32m     47\u001b[0m \u001b[39m.\u001b[39mmode(\u001b[39m'\u001b[39m\u001b[39moverwrite\u001b[39m\u001b[39m'\u001b[39m) \\\n\u001b[1;32m     48\u001b[0m \u001b[39m.\u001b[39mparquet(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00myellow_curated_dir\u001b[39m}\u001b[39;00m\u001b[39m2022/2022-\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(month)\u001b[39m.\u001b[39mzfill(\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "payment_cols = ['fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge', 'airport_fee']\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 2022\n",
    "for month in range(1,12):\n",
    "\n",
    "    year = 2022\n",
    "    sdf = spark.read.parquet(f\"{yellow_raw_dir}2022/2022-{str(month).zfill(2)}.parquet\")  \n",
    "\n",
    "    #laguardia_id = \n",
    "    #jfk_id = \n",
    "    \n",
    "    '''\n",
    "    sdf = sdf.withColumn(\n",
    "        'is_valid_record',\n",
    "        # when we have a positive distance/passenger/total amount then True\n",
    "        # else False\n",
    "        F.when(\n",
    "            (F.col('trip_distance') > 0)\n",
    "            & (F.col('passenger_count') > 0)\n",
    "            & (F.col('total_amount') > 0),\n",
    "            True\n",
    "        ).otherwise(False)\n",
    "    )\n",
    "    '''\n",
    "    \n",
    "    # may have to go through data and apply invalid record boolean attribute first for more complex business logic checking such as airport fee matching pickup at laguardia / jfk\n",
    "    \n",
    "    # remove invalid records by applying business logic\n",
    "    sdf = \\\n",
    "    sdf.where(\n",
    "        (F.year(F.col('tpep_pickup_datetime')) == year) # ensure that this trip was initiated within the correct year (assuming a trip belongs to a year based on pickup time)\n",
    "        (F.month(F.col('tpep_pickup_datetime')) == month)  # ensure that this trip was initiated within the correct month (assuming a trip belongs to a month based on pickup time)\n",
    "        & (F.unix_timestamp('tpep_pickup_datetime') < F.unix_timestamp('tpep_dropoff_datetime')) # make sure pickup time is earlier than dropoff time\n",
    "        & (F.col('passenger_count') > 0) # ensure non-zero passenger count, but also within 6 people based on the law\n",
    "        & (F.col('passenger_count') <= 6)\n",
    "        & (F.col('trip_distance') > 0.25) # remove extremely short / negative trip distance based on distance people are willing to walk before taking a taxi\n",
    "        & (F.col('trip_distance') < 300) # remove extreme outliers for trip distance (trips around and above this distance generally appear invalid / erroneous)\n",
    "        & (F.col('pulocationid') >= 1) # ensure trips are only within the specified range of locations\n",
    "        & (F.col('pulocationid') <= 263)\n",
    "        & (F.col('dolocationid') >= 1)\n",
    "        & (F.col('dolocationid') <= 263)\n",
    "        & (F.col('total_amount') >= 2.50) # ensure non-negative fees, minimum of $2.50 for standard fares\n",
    "        & (F.col('fare_amount') >= 2.50) \n",
    "        & (F.col('tip_amount') >= 0) \n",
    "        & (F.col('tolls_amount') >= 0)\n",
    "        & (F.col('payment_type') == 1) # include only credit card payments as cash tips are not included in this data\n",
    "        & (F.col('total_amount') == sum(sdf[col] for col in payment_cols)) # check the total amount equals the sum of all other fees\n",
    "    ).where(\n",
    "        (F.col('vendorid') == 1) # check for valid vendor id\n",
    "        | (F.col('vendorid') == 2)  \n",
    "    )\n",
    "    .where(\n",
    "        (F.col('ratecodeid') == 1) # standard, JFK, and Newark rates suitable for this research based on the locations covered\n",
    "        | (F.col('ratecodeid') == 2)  \n",
    "        | (F.col('ratecodeid') == 3)\n",
    "    ).where(\n",
    "        (F.col('mta_tax') == 0.50) # $0.50 MTA tax for trips that end in NYC (but not Newark).\n",
    "        & (F.col('dolocationid') != 1)  \n",
    "        | (F.col('mta_tax') == 0)\n",
    "        & (F.col('dolocationid') == 1)  \n",
    "    ).where(\n",
    "        (F.col('improvement_surcharge') == 0) # check improvement surcharge is either $0 or $0.30\n",
    "        | (F.col('improvement_surcharge') == 0.30)\n",
    "    ).where(\n",
    "        (F.col('congestion_surcharge') == 0) # check congestion surcharge is either $0 or $2.50 for yellow taxis\n",
    "        | (F.col('congestion_surcharge') == 2.50)\n",
    "    ).where(\n",
    "        (F.col('extra') == 1.00) # ensure rush hour surcharge only applied for trips during rush hour, \n",
    "        & (F.hour('tpep_pickup_datetime') >= 16)\n",
    "        & (F.hour('tpep_pickup_datetime') < 20)\n",
    "        | (F.col('extra') == 1.00) \n",
    "        & (F.hour('tpep_dropoff_datetime') >= 16)\n",
    "        & (F.hour('tpep_dropoff_datetime') < 20)\n",
    "        | (F.col('extra') == 0)  # no surcharge for trips that don't fall within rush hour or overnight time slots\n",
    "        & (F.hour('tpep_pickup_datetime') >= 6)\n",
    "        & (F.hour('tpep_pickup_datetime') < 16)\n",
    "        & (F.hour('tpep_dropoff_datetime') >= 6)\n",
    "        & (F.hour('tpep_dropoff_datetime') < 16)\n",
    "        | (F.col('extra') == 0.50) # ensure overnight surcharge only applied for overnight trips (rush hour surcharge takes precedent over overnight surcharge when a trip falls within both time slots)\n",
    "        & (F.hour('tpep_pickup_datetime') >= 20) \n",
    "        & (F.hour('tpep_pickup_datetime') < 6)\n",
    "        | (F.col('extra') == 0.50)\n",
    "        & (F.hour('tpep_pickup_datetime') >= 20)\n",
    "        | (F.hour('tpep_dropoff_datetime') < 6)\n",
    "    ).where(\n",
    "        (F.col('airport_fee') == 0) # ensure airport fee was only applied for pickup at JFK or LaGuardia\n",
    "        & (F.col('pulocationid') != jfk_id)\n",
    "        & (F.col('pulocationid') != laguardia_id)\n",
    "        | (F.col('pulocationid') == jfk_id)\n",
    "        & (F.col('airport_fee') == 1.25)\n",
    "        | (F.col('pulocationid') == laguardia_id)\n",
    "        & (F.col('airport_fee') == 1.25)  \n",
    "    ).drop( \n",
    "        'store_and_fwd_flag', 'total_amount' # remove store_and_fwd flag (as this is useless for our analysis) and total_amount (as this can be calculated from the other features)\n",
    "    ).dropna('any') # remove any records containing NULL values as it will be assumed these are invalid / erroneous entries and PySpark ML is unable to handle NULL values\n",
    "    \n",
    "    '''\n",
    "    sdf_cleaned = sdf_cleaned.withColumn(\n",
    "        'store_and_fwd_flag',\n",
    "        (F.col(\"store_and_fwd_flag\") == 'Y').cast('BOOLEAN')\n",
    "    )\n",
    "    '''\n",
    "        \n",
    "    sdf \\\n",
    "    .coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet(f\"{yellow_curated_dir}2022/2022-{str(month).zfill(2)}.parquet\")\n",
    "\n",
    "'''\n",
    "# 2023\n",
    "for month in range(1,5):\n",
    "\n",
    "    year = 2023\n",
    "    sdf_cleaned = spark.read.parquet(f\"{yellow_raw_dir}2023/2023-{str(month).zfill(2)}.parquet\")\n",
    "    \n",
    "    # apply business logic\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "       \n",
    "    sdf_cleaned \\\n",
    "    .coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet(f\"{yellow_curated_dir}2023/2023-{str(month).zfill(2)}.parquet\")\n",
    "'''    \n",
    "    \n",
    "'''\n",
    "# renaming\n",
    "sdf.withColumnRenamed(\n",
    "    'column_from',\n",
    "    'column_to'\n",
    ")\n",
    "\n",
    "# example 1 for converting data types\n",
    "sdf.withColumn(\n",
    "    'column_to',\n",
    "    F.col('column_from').cast('data type')\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.show(1, vertical=True, truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check curated 2022 data\n",
    "\n",
    "sdf1 = spark.read.schema(sdf_schema).parquet('../data/cleaned/tlc/yellow/2022/*')\n",
    "\n",
    "sdf1.show(1, vertical=True, truncate=100)\n",
    "\n",
    "''' checking raw vs cleaned dataset shape and raw dataset shape of jan 2022\n",
    "sdf2 = spark.read.parquet('../data/raw/tlc/yellow/2022')\n",
    "\n",
    "sdf2.show(1, vertical=True, truncate=100)\n",
    "\n",
    "print(sdf1.count())\n",
    "\n",
    "print(sdf2.count())\n",
    "\n",
    "sdf = spark.read.parquet('../data/raw/tlc/yellow/2022/2022-01.parquet')\n",
    "\n",
    "sdf.show(1, vertical=True, truncate=100)\n",
    "\n",
    "print(sdf.count())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check curated 2023 data\n",
    "\n",
    "sdf = spark.read.schema(sdf_schema).parquet('../data/cleaned/tlc/yellow/2023/*')\n",
    "\n",
    "sdf.show(1, vertical=True, truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Green Taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for curated data\n",
    "\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "if not os.path.exists('../data/curated/'):\n",
    "    os.makedirs('../data/curated/')\n",
    "    \n",
    "if not os.path.exists('../data/curated/tlc'):\n",
    "    os.makedirs('../data/curated/tlc')\n",
    "    \n",
    "if not os.path.exists('../data/curated/tlc/green'):\n",
    "    os.makedirs('../data/curated/tlc/green')\n",
    "    \n",
    "if not os.path.exists('../data/curated/tlc/green/2021'):\n",
    "    os.makedirs('../data/curated/tlc/green/2021')   \n",
    "    \n",
    "if not os.path.exists('../data/curated/tlc/green/2022'):\n",
    "    os.makedirs('../data/curated/tlc/green/2022')\n",
    "    \n",
    "if not os.path.exists('../data/curated/tlc/green/2023'):\n",
    "    os.makedirs('../data/curated/tlc/green/2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_raw_dir = '../data/raw/tlc/green/'\n",
    "\n",
    "sdf_green_2022_01 = spark.read.parquet(f\"{green_raw_dir}2022/2022-01.parquet\")\n",
    "\n",
    "sdf_green_2022_all = spark.read.parquet(f\"{green_raw_dir}2022/*\")\n",
    "\n",
    "sdf_green_2023_01 = spark.read.parquet(f\"{green_raw_dir}2023/2023-01.parquet\")\n",
    "\n",
    "sdf_green_2023_02 = spark.read.parquet(f\"{green_raw_dir}2023/2023-02.parquet\")\n",
    "\n",
    "#sdf_green_2022_all = spark.read.parquet('../data/raw/green/2022')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('vendorid', IntegerType(), True), StructField('lpep_pickup_datetime', TimestampNTZType(), True), StructField('lpep_dropoff_datetime', TimestampNTZType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('ratecodeid', IntegerType(), True), StructField('pulocationid', IntegerType(), True), StructField('dolocationid', IntegerType(), True), StructField('passenger_count', IntegerType(), True), StructField('trip_distance', DoubleType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('payment_type', LongType(), True), StructField('trip_type', LongType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_green_2022_01.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('lpep_pickup_datetime', TimestampNTZType(), True), StructField('lpep_dropoff_datetime', TimestampNTZType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('RatecodeID', DoubleType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('passenger_count', DoubleType(), True), StructField('trip_distance', DoubleType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('ehail_fee', IntegerType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('payment_type', DoubleType(), True), StructField('trip_type', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_green_2022_all.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('lpep_pickup_datetime', TimestampNTZType(), True), StructField('lpep_dropoff_datetime', TimestampNTZType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('RatecodeID', DoubleType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('passenger_count', DoubleType(), True), StructField('trip_distance', DoubleType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('ehail_fee', IntegerType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('payment_type', DoubleType(), True), StructField('trip_type', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_green_2023_01.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', IntegerType(), True), StructField('lpep_pickup_datetime', TimestampNTZType(), True), StructField('lpep_dropoff_datetime', TimestampNTZType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('RatecodeID', LongType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('ehail_fee', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('payment_type', LongType(), True), StructField('trip_type', LongType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_green_2023_02.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trips: \n",
      "2463931\n",
      "Credit card payment trips with valid total: \n",
      "1039104\n",
      "Trips with valid total: \n",
      "1399649\n",
      "Cash payment trips with valid total: \n",
      "348632\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sdf_green_2022_01' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCash payment trips with valid total: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(sdf_yellow_2022_01\u001b[39m.\u001b[39mwhere((F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mpayment_type\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39msum\u001b[39m(sdf_yellow_2022_01[col] \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m payment_cols)))\u001b[39m.\u001b[39mcount())\n\u001b[0;32m---> 22\u001b[0m sdf_green_2022_01\u001b[39m.\u001b[39mwhere(\n\u001b[1;32m     23\u001b[0m     (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mcongestion_surcharge\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m) \n\u001b[1;32m     24\u001b[0m     )\u001b[39m.\u001b[39mshow(\u001b[39m5\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[39m#sdf_yellow_2022_01.filter(F.col('passenger_count') == 5).limit(5)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sdf_green_2022_01' is not defined"
     ]
    }
   ],
   "source": [
    "# Test filters here\n",
    "#sdf_green_2022_01.schema\n",
    "\n",
    "payment_cols = ['fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge']\n",
    "\n",
    "print(\"Total trips: \")\n",
    "\n",
    "print(sdf_green_2022_01.count())\n",
    "\n",
    "print(\"Credit card payment trips with valid total: \")\n",
    "\n",
    "print(sdf_green_2022_01.where((F.col('payment_type') == 1) & (F.col('total_amount') == sum(sdf_green_2022_01[col] for col in payment_cols))).count())\n",
    "\n",
    "print(\"Trips with valid total: \")\n",
    "\n",
    "print(sdf_green_2022_01.where(F.col('total_amount') == sum(sdf_green_2022_01[col] for col in payment_cols)).count())\n",
    "\n",
    "print(\"Cash payment trips with valid total: \")\n",
    "\n",
    "print(sdf_green_2022_01.where((F.col('payment_type') == 2) & (F.col('total_amount') == sum(sdf_green_2022_01[col] for col in payment_cols))).count())\n",
    "\n",
    "sdf_green_2022_01.where(\n",
    "    (F.col('congestion_surcharge') != 0) \n",
    ")\n",
    "\n",
    "#sdf_green_2022_01.filter(F.col('passenger_count') == 5).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>vendorid</th><th>lpep_pickup_datetime</th><th>lpep_dropoff_datetime</th><th>store_and_fwd_flag</th><th>ratecodeid</th><th>pulocationid</th><th>dolocationid</th><th>passenger_count</th><th>trip_distance</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>payment_type</th><th>trip_type</th><th>congestion_surcharge</th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+---------+--------------------+\n",
       "|vendorid|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
       "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+---------+--------------------+\n",
       "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+---------+--------------------+"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain a list of 'yellow zones' (zones in which only yellow taxis may respond to street hails)\n",
    "\n",
    "taxi_zones = spark.read.parquet('../data/raw/tlc/taxi_zones/taxi_zone_lookup.parquet/')\n",
    "\n",
    "yellow_zones = taxi_zones.where(\n",
    "    F.col('service_zone') == 'Yellow Zone'\n",
    ").select('locationid').rdd.map(lambda x: x.locationid).collect()\n",
    "\n",
    "yellow_zones = list(map(int, yellow_zones))\n",
    "\n",
    "sdf_green_2022_01.where(\n",
    "    (~F.col('pulocationid').isin(yellow_zones)) # only keep street hail entries that aren't recorded as pickup in yellow zones (as green taxis can't respond to street hails in these zones)\n",
    "        | (F.col('pulocationid').isin(yellow_zones))\n",
    "        & (F.col('trip_type') == 2)\n",
    ").where(\n",
    "    (F.col('pulocationid').isin(yellow_zones))\n",
    "    & (F.col('trip_type') == 1)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use business logic to filter and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[61], line 14\u001b[0m\n",
      "\u001b[1;32m      9\u001b[0m sdf_cleaned \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mparquet(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00myellow_cleaned_dir\u001b[39m}\u001b[39;00m\u001b[39m2022/2022-\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(month)\u001b[39m.\u001b[39mzfill(\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.parquet\u001b[39m\u001b[39m\"\u001b[39m)  \n",
      "\u001b[1;32m     11\u001b[0m \u001b[39m# remove invalid records by applying business logic\u001b[39;00m\n",
      "\u001b[1;32m     12\u001b[0m sdf_cleaned \u001b[39m=\u001b[39m \\\n",
      "\u001b[1;32m     13\u001b[0m sdf_cleaned\u001b[39m.\u001b[39mwhere(\n",
      "\u001b[0;32m---> 14\u001b[0m     (F\u001b[39m.\u001b[39;49myear(F\u001b[39m.\u001b[39;49mcol(\u001b[39m'\u001b[39;49m\u001b[39mtpep_pickup_datetime\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39m==\u001b[39;49m year) \u001b[39m# ensure that this trip was initiated within the correct year (assuming a trip belongs to a month based on pickup time)\u001b[39;49;00m\n",
      "\u001b[1;32m     15\u001b[0m     (F\u001b[39m.\u001b[39;49mmonth(F\u001b[39m.\u001b[39;49mcol(\u001b[39m'\u001b[39;49m\u001b[39mtpep_pickup_datetime\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39m==\u001b[39;49m month)  \u001b[39m# ensure that this trip was initiated within the correct month (assuming a trip belongs to a month based on pickup time)\u001b[39;00m\n",
      "\u001b[1;32m     16\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39munix_timestamp(\u001b[39m'\u001b[39m\u001b[39mtpep_pickup_datetime\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m<\u001b[39m F\u001b[39m.\u001b[39munix_timestamp(\u001b[39m'\u001b[39m\u001b[39mtpep_dropoff_datetime\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m# make sure pickup time is earlier than dropoff time\u001b[39;00m\n",
      "\u001b[1;32m     17\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mpassenger_count\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m# ensure non-zero passenger count, trip distance and total amount\u001b[39;00m\n",
      "\u001b[1;32m     18\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtrip_distance\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\n",
      "\u001b[1;32m     19\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n",
      "\u001b[1;32m     20\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n",
      "\u001b[1;32m     21\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n",
      "\u001b[1;32m     22\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n",
      "\u001b[1;32m     23\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n",
      "\u001b[1;32m     24\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \n",
      "\u001b[1;32m     25\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mpayment_type\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m# include only credit card payments as cash tips are not included\u001b[39;00m\n",
      "\u001b[1;32m     26\u001b[0m     \u001b[39m&\u001b[39m (F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mtotal_amount\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39msum\u001b[39m(sdf_yellow_2022_01[col] \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m payment_cols)) \u001b[39m# check the total amount equals the sum of all other fees\u001b[39;00m\n",
      "\u001b[1;32m     27\u001b[0m     \n",
      "\u001b[1;32m     28\u001b[0m )\u001b[39m.\u001b[39mwithColumn(\n",
      "\u001b[1;32m     29\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mstore_and_fwd_flag\u001b[39m\u001b[39m'\u001b[39m,\n",
      "\u001b[1;32m     30\u001b[0m     (F\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mstore_and_fwd_flag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mcast(\u001b[39m'\u001b[39m\u001b[39mBOOLEAN\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m     31\u001b[0m )\n",
      "\u001b[1;32m     33\u001b[0m sdf_cleaned \u001b[39m=\u001b[39m sdf_cleaned\u001b[39m.\u001b[39mwithColumn(\n",
      "\u001b[1;32m     34\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mstore_and_fwd_flag\u001b[39m\u001b[39m'\u001b[39m,\n",
      "\u001b[1;32m     35\u001b[0m     (F\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mstore_and_fwd_flag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mcast(\u001b[39m'\u001b[39m\u001b[39mBOOLEAN\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m     36\u001b[0m )\n",
      "\u001b[1;32m     44\u001b[0m sdf_cleaned \\\n",
      "\u001b[1;32m     45\u001b[0m \u001b[39m.\u001b[39mcoalesce(\u001b[39m1\u001b[39m) \\\n",
      "\u001b[1;32m     46\u001b[0m \u001b[39m.\u001b[39mwrite \\\n",
      "\u001b[1;32m     47\u001b[0m \u001b[39m.\u001b[39mmode(\u001b[39m'\u001b[39m\u001b[39moverwrite\u001b[39m\u001b[39m'\u001b[39m) \\\n",
      "\u001b[1;32m     48\u001b[0m \u001b[39m.\u001b[39mparquet(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00myellow_curated_dir\u001b[39m}\u001b[39;00m\u001b[39m2022/2022-\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(month)\u001b[39m.\u001b[39mzfill(\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "payment_cols = ['fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge']\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "green_raw_dir = '../data/raw/tlc/green/'\n",
    "    \n",
    "green_curated_dir = '../data/curated/tlc/green/'\n",
    "\n",
    "YEARS = ['2021', '2022', '2023']\n",
    "\n",
    "for year in YEARS:\n",
    "    if (year == '2021'):\n",
    "        MONTHS = [12]\n",
    "    if (year == '2022'):\n",
    "        MONTHS = range(1,13)\n",
    "    if (year == '2023'):   \n",
    "        MONTHS = range(1,5) \n",
    "    for month in MONTHS:\n",
    "        \n",
    "        sdf = spark.read.parquet(f\"{green_raw_dir}{year}/{year}-{str(month).zfill(2)}.parquet\")  \n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        sdf = sdf.withColumn(\n",
    "            'is_valid_record',\n",
    "            # when we have a positive distance/passenger/total amount then True\n",
    "            # else False\n",
    "            F.when(\n",
    "                (F.col('trip_distance') > 0)\n",
    "                & (F.col('passenger_count') > 0)\n",
    "                & (F.col('total_amount') > 0),\n",
    "                True\n",
    "            ).otherwise(False)\n",
    "        )\n",
    "        '''\n",
    "        \n",
    "        # may have to go through data and apply invalid record boolean attribute first for more complex business logic checking such as airport fee matching pickup at laguardia / jfk\n",
    "        \n",
    "        # remove invalid records by applying business logic\n",
    "        sdf = \\\n",
    "        sdf.where(\n",
    "            (F.year(F.col('tpep_pickup_datetime')) == year) # ensure that this trip was initiated within the correct year (assuming a trip belongs to a year based on pickup time)\n",
    "            (F.month(F.col('tpep_pickup_datetime')) == month)  # ensure that this trip was initiated within the correct month (assuming a trip belongs to a month based on pickup time)\n",
    "            & (F.unix_timestamp('tpep_pickup_datetime') < F.unix_timestamp('tpep_dropoff_datetime')) # make sure pickup time is earlier than dropoff time\n",
    "            & (F.col('passenger_count') > 0) # ensure non-zero passenger count, but also within 6 people based on the law\n",
    "            & (F.col('passenger_count') <= 6)\n",
    "            & (F.col('trip_distance') > 0.25) # remove extremely short / negative trip distance based on distance people are willing to walk before taking a taxi\n",
    "            & (F.col('trip_distance') < 300) # remove extreme outliers for trip distance (trips around and above this distance generally appear invalid / erroneous)\n",
    "            & (F.col('pulocationid') >= 1) # ensure trips are only within the specified range of locations\n",
    "            & (F.col('pulocationid') <= 263)\n",
    "            & (F.col('dolocationid') >= 1)\n",
    "            & (F.col('dolocationid') <= 263)\n",
    "            & (F.col('total_amount') >= 2.50) # ensure non-negative fees, minimum of $2.50 for standard fares\n",
    "            & (F.col('fare_amount') >= 2.50) \n",
    "            & (F.col('tip_amount') >= 0) \n",
    "            & (F.col('tolls_amount') >= 0)\n",
    "            & (F.col('payment_type') == 1) # include only credit card payments as cash tips are not included in this data\n",
    "            & (F.col('total_amount') == sum(sdf[col] for col in payment_cols)) # check the total amount equals the sum of all other fees\n",
    "        ).where(\n",
    "            (F.col('vendorid') == 1) # check for valid vendor id\n",
    "            | (F.col('vendorid') == 2)  \n",
    "        )\n",
    "        .where(\n",
    "            (F.col('ratecodeid') == 1) # standard, JFK, and Newark rates suitable for this research based on the locations covered\n",
    "            | (F.col('ratecodeid') == 2)  \n",
    "            | (F.col('ratecodeid') == 3)\n",
    "        ).where(\n",
    "            (F.col('mta_tax') == 0.50) # $0.50 MTA tax for trips that end in NYC (but not Newark according to taxi fare page).\n",
    "            & (F.col('dolocationid') != 1)  \n",
    "            | (F.col('mta_tax') == 0)\n",
    "            & (F.col('dolocationid') == 1)  \n",
    "        ).where(\n",
    "            (F.col('improvement_surcharge') == 0) # check improvement surcharge is either $0 or $0.30\n",
    "            | (F.col('improvement_surcharge') == 0.30)\n",
    "        ).where(\n",
    "            (F.col('congestion_surcharge') == 0) # check congestion surcharge is either $0 or $2.75 for green taxis\n",
    "            | (F.col('congestion_surcharge') == 2.75)\n",
    "        ).where(\n",
    "            (F.col('extra') == 1.00) # ensure rush hour surcharge only applied for trips during rush hour, \n",
    "            & (F.hour('tpep_pickup_datetime') >= 16)\n",
    "            & (F.hour('tpep_pickup_datetime') < 20)\n",
    "            | (F.col('extra') == 1.00) \n",
    "            & (F.hour('tpep_dropoff_datetime') >= 16)\n",
    "            & (F.hour('tpep_dropoff_datetime') < 20)\n",
    "            | (F.col('extra') == 0)  # no surcharge for trips that don't fall within rush hour or overnight time slots\n",
    "            & (F.hour('tpep_pickup_datetime') >= 6)\n",
    "            & (F.hour('tpep_pickup_datetime') < 16)\n",
    "            & (F.hour('tpep_dropoff_datetime') >= 6)\n",
    "            & (F.hour('tpep_dropoff_datetime') < 16)\n",
    "            | (F.col('extra') == 0.50) # ensure overnight surcharge only applied for overnight trips (rush hour surcharge takes precedent over overnight surcharge when a trip falls within both time slots)\n",
    "            & (F.hour('tpep_pickup_datetime') >= 20) \n",
    "            & (F.hour('tpep_pickup_datetime') < 6)\n",
    "            | (F.col('extra') == 0.50)\n",
    "            & (F.hour('tpep_pickup_datetime') >= 20)\n",
    "            | (F.hour('tpep_dropoff_datetime') < 6)\n",
    "        )where(\n",
    "            (~F.col('pulocationid').isin(yellow_zones)) # only keep street hail entries (trip_type == 1) that aren't recorded as pickup in yellow zones \n",
    "            | (F.col('pulocationid').isin(yellow_zones)) # (as green taxis can't respond to street hails in these zones)\n",
    "            & (F.col('trip_type') == 2)\n",
    "        ).drop( \n",
    "            'store_and_fwd_flag', 'total_amount' # remove store_and_fwd flag (as this is useless for our analysis) and total_amount (as this can be calculated from the other features)\n",
    "        ).dropna('any') # remove any records containing NULL values as it will be assumed these are invalid / erroneous entries and PySpark ML is unable to handle NULL values\n",
    "        \n",
    "        '''\n",
    "        sdf_cleaned = sdf_cleaned.withColumn(\n",
    "            'store_and_fwd_flag',\n",
    "            (F.col(\"store_and_fwd_flag\") == 'Y').cast('BOOLEAN')\n",
    "        )\n",
    "        '''\n",
    "            \n",
    "        sdf \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet(f\"{green_curated_dir}2022/2022-{str(month).zfill(2)}.parquet\")\n",
    "\n",
    "    \n",
    "'''\n",
    "# renaming\n",
    "sdf.withColumnRenamed(\n",
    "    'column_from',\n",
    "    'column_to'\n",
    ")\n",
    "\n",
    "# example 1 for converting data types\n",
    "sdf.withColumn(\n",
    "    'column_to',\n",
    "    F.col('column_from').cast('data type')\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.show(1, vertical=True, truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check curated 2022 data\n",
    "\n",
    "sdf1 = spark.read.schema(sdf_schema).parquet('../data/cleaned/tlc/yellow/2022/*')\n",
    "\n",
    "sdf1.show(1, vertical=True, truncate=100)\n",
    "\n",
    "''' checking raw vs cleaned dataset shape and raw dataset shape of jan 2022\n",
    "sdf2 = spark.read.parquet('../data/raw/tlc/yellow/2022')\n",
    "\n",
    "sdf2.show(1, vertical=True, truncate=100)\n",
    "\n",
    "print(sdf1.count())\n",
    "\n",
    "print(sdf2.count())\n",
    "\n",
    "sdf = spark.read.parquet('../data/raw/tlc/yellow/2022/2022-01.parquet')\n",
    "\n",
    "sdf.show(1, vertical=True, truncate=100)\n",
    "\n",
    "print(sdf.count())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " vendorid              | 1                   \n",
      " lpep_pickup_datetime  | 2022-03-01 00:24:14 \n",
      " lpep_dropoff_datetime | 2022-03-01 00:34:04 \n",
      " store_and_fwd_flag    | N                   \n",
      " ratecodeid            | 1                   \n",
      " pulocationid          | 74                  \n",
      " dolocationid          | 151                 \n",
      " passenger_count       | 1                   \n",
      " trip_distance         | 2.3                 \n",
      " fare_amount           | 9.5                 \n",
      " extra                 | 0.5                 \n",
      " mta_tax               | 0.5                 \n",
      " tip_amount            | 0.0                 \n",
      " tolls_amount          | 0.0                 \n",
      " ehail_fee             | null                \n",
      " improvement_surcharge | 0.3                 \n",
      " total_amount          | 10.8                \n",
      " payment_type          | 2                   \n",
      " trip_type             | 1                   \n",
      " congestion_surcharge  | 0.0                 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" checking raw vs cleaned dataset shape and raw dataset shape of jan 2022\\nsdf2 = spark.read.parquet('../data/raw/tlc/yellow/2022')\\n\\nsdf2.show(1, vertical=True, truncate=100)\\n\\nprint(sdf1.count())\\n\\nprint(sdf2.count())\\n\\nsdf = spark.read.parquet('../data/raw/tlc/yellow/2022/2022-01.parquet')\\n\\nsdf.show(1, vertical=True, truncate=100)\\n\\nprint(sdf.count())\\n\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check schema of 2022 cleaned data\n",
    "\n",
    "sdf1 = spark.read.schema(sdf_schema).parquet('../data/cleaned/tlc/green/2022/*')\n",
    "\n",
    "sdf1.show(1, vertical=True, truncate=100)\n",
    "\n",
    "''' checking raw vs cleaned dataset shape and raw dataset shape of jan 2022\n",
    "sdf2 = spark.read.parquet('../data/raw/tlc/yellow/2022')\n",
    "\n",
    "sdf2.show(1, vertical=True, truncate=100)\n",
    "\n",
    "print(sdf1.count())\n",
    "\n",
    "print(sdf2.count())\n",
    "\n",
    "sdf = spark.read.parquet('../data/raw/tlc/yellow/2022/2022-01.parquet')\n",
    "\n",
    "sdf.show(1, vertical=True, truncate=100)\n",
    "\n",
    "print(sdf.count())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " vendorid              | 2                   \n",
      " lpep_pickup_datetime  | 2023-03-01 00:25:10 \n",
      " lpep_dropoff_datetime | 2023-03-01 00:35:47 \n",
      " store_and_fwd_flag    | N                   \n",
      " ratecodeid            | 1                   \n",
      " pulocationid          | 82                  \n",
      " dolocationid          | 196                 \n",
      " passenger_count       | 1                   \n",
      " trip_distance         | 2.36                \n",
      " fare_amount           | 13.5                \n",
      " extra                 | 1.0                 \n",
      " mta_tax               | 0.5                 \n",
      " tip_amount            | 0.0                 \n",
      " tolls_amount          | 0.0                 \n",
      " ehail_fee             | null                \n",
      " improvement_surcharge | 1.0                 \n",
      " total_amount          | 16.0                \n",
      " payment_type          | 2                   \n",
      " trip_type             | 1                   \n",
      " congestion_surcharge  | 0.0                 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# double check schema of 2023 cleaned data\n",
    "\n",
    "sdf = spark.read.schema(sdf_schema).parquet('../data/cleaned/tlc/green/2023/*')\n",
    "\n",
    "sdf.show(1, vertical=True, truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for cleaned data\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists('../data/cleaned/'):\n",
    "    os.makedirs('../data/cleaned/')\n",
    "    \n",
    "if not os.path.exists('../data/cleaned/tlc'):\n",
    "    os.makedirs('../data/cleaned/tlc')\n",
    "    \n",
    "if not os.path.exists('../data/cleaned/tlc/taxi_zones'):\n",
    "    os.makedirs('../data/cleaned/tlc/taxi_zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_lookup = spark.read.option(\"header\",True) \\\n",
    "                   .csv(\"../data/raw/tlc/taxi_zones/taxi+_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "\n",
      "StructType([StructField('LocationID', StringType(), True), StructField('Borough', StringType(), True), StructField('Zone', StringType(), True), StructField('service_zone', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "print(taxi_zone_lookup.limit(5))\n",
    "\n",
    "print(taxi_zone_lookup.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just need to convert the column names to lowercase for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|locationid|      borough|                zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "\n",
      "StructType([StructField('locationid', StringType(), True), StructField('borough', StringType(), True), StructField('zone', StringType(), True), StructField('service_zone', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# converting to lower case\n",
    "consistent_col_casing = [F.col(col_name).alias(col_name.lower()) for col_name in taxi_zone_lookup.columns]\n",
    "taxi_zone_lookup = taxi_zone_lookup.select(*consistent_col_casing)\n",
    "\n",
    "print(taxi_zone_lookup.limit(5))\n",
    "print(taxi_zone_lookup.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save cleaned data as parquet\n",
    "taxi_zone_lookup \\\n",
    "    .coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet('../data/cleaned/tlc/taxi_zones/taxi_zone_lookup.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of +----------+-------------+--------------------+------------+\n",
       "|locationid|      borough|                zone|service_zone|\n",
       "+----------+-------------+--------------------+------------+\n",
       "|         1|          EWR|      Newark Airport|         EWR|\n",
       "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
       "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
       "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
       "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
       "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
       "|         7|       Queens|             Astoria|   Boro Zone|\n",
       "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
       "|         9|       Queens|          Auburndale|   Boro Zone|\n",
       "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
       "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
       "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
       "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
       "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
       "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
       "|        16|       Queens|             Bayside|   Boro Zone|\n",
       "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
       "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
       "|        19|       Queens|           Bellerose|   Boro Zone|\n",
       "|        20|        Bronx|             Belmont|   Boro Zone|\n",
       "+----------+-------------+--------------------+------------+\n",
       "only showing top 20 rows\n",
       ">"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check cleaned data\n",
    "taxi_zone_lookup = spark.read.parquet('../data/cleaned/tlc/taxi_zones/taxi_zone_lookup.parquet')\n",
    "\n",
    "taxi_zone_lookup.printSchema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motor Vehicle Collisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subway Entrances and Exits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subway Hourly Ridership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus Hourly Ridership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hotel Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airbnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
