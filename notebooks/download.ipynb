{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval / Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLC Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS = ('2022', '2023')\n",
    "\n",
    "MONTHS = range(1, 13)\n",
    "\n",
    "VEHICLE_TYPES = ('yellow', 'green', 'fhvhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# navigate to the raw data directory\n",
    "output_relative_dir = '../data/raw/tlc'\n",
    "\n",
    "# check if it exists as it makedir will raise an error if it does exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    \n",
    "# now, for each type of data set we will need, we will create the paths\n",
    "for type in VEHICLE_TYPES:\n",
    "    for year in YEARS:\n",
    "        if not os.path.exists(output_relative_dir + type + '/' + year):\n",
    "            os.makedirs(output_relative_dir + type + '/' + year)\n",
    "\n",
    "if not os.path.exists(output_relative_dir + 'taxi_zones'):\n",
    "    os.makedirs(output_relative_dir + 'taxi_zones')\n",
    "\n",
    "if not os.path.exists('../data/raw/mv_collisions'):\n",
    "    os.makedirs('../data/raw/mv_collisions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the URL template as of 07/2023\n",
    "URL_TEMPLATE = \"https://d37ci6vzurychx.cloudfront.net/trip-data/\"#vehicleType_tripdata_year-month.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin yellow\n",
      "Begin year 2022\n",
      "Begin month 01\n",
      "Completed month 01\n",
      "Begin month 02\n",
      "Completed month 02\n",
      "Begin month 03\n",
      "Completed month 03\n",
      "Begin month 04\n",
      "Completed month 04\n",
      "Begin month 05\n",
      "Completed month 05\n",
      "Begin month 06\n",
      "Completed month 06\n",
      "Begin month 07\n",
      "Completed month 07\n",
      "Begin month 08\n",
      "Completed month 08\n",
      "Begin month 09\n",
      "Completed month 09\n",
      "Begin month 10\n",
      "Completed month 10\n",
      "Begin month 11\n",
      "Completed month 11\n",
      "Begin month 12\n",
      "Completed month 12\n",
      "Completed year 2022\n",
      "Begin year 2023\n",
      "Begin month 01\n",
      "Completed month 01\n",
      "Begin month 02\n",
      "Completed month 02\n",
      "Begin month 03\n",
      "Completed month 03\n",
      "Begin month 04\n",
      "Completed month 04\n",
      "Completed year 2023\n",
      "Completed yellow\n",
      "##########################################################\n",
      "Begin green\n",
      "Begin year 2022\n",
      "Begin month 01\n",
      "Completed month 01\n",
      "Begin month 02\n",
      "Completed month 02\n",
      "Begin month 03\n",
      "Completed month 03\n",
      "Begin month 04\n",
      "Completed month 04\n",
      "Begin month 05\n",
      "Completed month 05\n",
      "Begin month 06\n",
      "Completed month 06\n",
      "Begin month 07\n",
      "Completed month 07\n",
      "Begin month 08\n",
      "Completed month 08\n",
      "Begin month 09\n",
      "Completed month 09\n",
      "Begin month 10\n",
      "Completed month 10\n",
      "Begin month 11\n",
      "Completed month 11\n",
      "Begin month 12\n",
      "Completed month 12\n",
      "Completed year 2022\n",
      "Begin year 2023\n",
      "Begin month 01\n",
      "Completed month 01\n",
      "Begin month 02\n",
      "Completed month 02\n",
      "Begin month 03\n",
      "Completed month 03\n",
      "Begin month 04\n",
      "Completed month 04\n",
      "Completed year 2023\n",
      "Completed green\n",
      "##########################################################\n",
      "Begin fhvhv\n",
      "Begin year 2022\n",
      "Begin month 01\n",
      "Completed month 01\n",
      "Begin month 02\n",
      "Completed month 02\n",
      "Begin month 03\n",
      "Completed month 03\n",
      "Begin month 04\n",
      "Completed month 04\n",
      "Begin month 05\n",
      "Completed month 05\n",
      "Begin month 06\n",
      "Completed month 06\n",
      "Begin month 07\n",
      "Completed month 07\n",
      "Begin month 08\n",
      "Completed month 08\n",
      "Begin month 09\n",
      "Completed month 09\n",
      "Begin month 10\n",
      "Completed month 10\n",
      "Begin month 11\n",
      "Completed month 11\n",
      "Begin month 12\n",
      "Completed month 12\n",
      "Completed year 2022\n",
      "Begin year 2023\n",
      "Begin month 01\n",
      "Completed month 01\n",
      "Begin month 02\n",
      "Completed month 02\n",
      "Begin month 03\n",
      "Completed month 03\n",
      "Begin month 04\n",
      "Completed month 04\n",
      "Completed year 2023\n",
      "Completed fhvhv\n",
      "##########################################################\n"
     ]
    }
   ],
   "source": [
    "# data output relative directory is `../data/raw/`\n",
    "\n",
    "# download tlc datasets\n",
    "for type in VEHICLE_TYPES:\n",
    "    print(f\"Begin {type}\")\n",
    "    for year in YEARS:\n",
    "        tlc_output_dir = output_relative_dir + type + '/' + year\n",
    "        print(f\"Begin year {year}\")\n",
    "        for month in MONTHS:\n",
    "            if (year == '2023' and month > 4):\n",
    "                break\n",
    "            # 0-fill i.e 1 -> 01, 2 -> 02, etc\n",
    "            month = str(month).zfill(2) \n",
    "            print(f\"Begin month {month}\")\n",
    "            \n",
    "            # generate url\n",
    "            url = f'{URL_TEMPLATE}{type}_tripdata_{year}-{month}.parquet'\n",
    "\n",
    "            # generate output location and filename\n",
    "            output_dir = f\"{tlc_output_dir}/{year}-{month}.parquet\"\n",
    "            # download\n",
    "            urlretrieve(url, output_dir) \n",
    "            \n",
    "            print(f\"Completed month {month}\")\n",
    "        print(f\"Completed year {year}\")\n",
    "    print(f\"Completed {type}\")\n",
    "    print(f\"##########################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download taxi zones csv and shapefile\n",
    "\n",
    "import zipfile\n",
    "\n",
    "output_dir = f\"{output_relative_dir}/taxi_zones/taxi+_zone_lookup.csv\"\n",
    "\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv'\n",
    "\n",
    "urlretrieve(url, output_dir) \n",
    "\n",
    "output_dir = f\"{output_relative_dir}/taxi_zones/taxi_zones.zip\"\n",
    "\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip'\n",
    "\n",
    "urlretrieve(url, output_dir) \n",
    "\n",
    "# unzip shapefile\n",
    "with zipfile.ZipFile(output_dir, 'r') as zip_ref:\n",
    "    zip_ref.extractall(f\"{output_relative_dir}/taxi_zones/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motor Vehicle Collisions NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/raw/mv_collisions/mv_collisions.csv',\n",
       " <http.client.HTTPMessage at 0x7f5c41786e90>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = 'https://data.cityofnewyork.us/api/views/h9gi-nx95/rows.csv?accessType=DOWNLOAD'\n",
    "\n",
    "output_dir = '../data/raw/mv_collisions/mv_collisions.csv'\n",
    "\n",
    "urlretrieve(url, output_dir) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.read_csv(output_dir, dtype={'ZIP CODE': object}).to_parquet('../data/raw/mv_collisions/mv_collisions.parquet')\n",
    "\n",
    "#mv_collisions = pd.read_csv(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing mv_collisions parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/07/28 23:02:19 WARN Utils: Your hostname, DESKTOP-SATV84A resolves to a loopback address: 127.0.1.1; using 172.26.254.29 instead (on interface eth0)\n",
      "23/07/28 23:02:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/28 23:02:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\") # fix timestamps loaded by spark\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_collisions = spark.read.parquet('../data/raw/mv_collisions/mv_collisions.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>ZIP CODE</th></tr>\n",
       "<tr><td>null</td></tr>\n",
       "<tr><td>null</td></tr>\n",
       "<tr><td>null</td></tr>\n",
       "<tr><td>11208</td></tr>\n",
       "<tr><td>11233</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+\n",
       "|ZIP CODE|\n",
       "+--------+\n",
       "|    null|\n",
       "|    null|\n",
       "|    null|\n",
       "|   11208|\n",
       "|   11233|\n",
       "+--------+"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_collisions.select('ZIP CODE').limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus Breakdowns / Delays NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/raw/bus_breakdowns_delays/bus_breakdowns_delays.csv',\n",
       " <http.client.HTTPMessage at 0x7f5b9e0dfe80>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "if not os.path.exists(output_relative_dir + 'bus_breakdowns_delays'):\n",
    "    os.makedirs(output_relative_dir + 'bus_breakdowns_delays')\n",
    "\n",
    "url = 'https://data.cityofnewyork.us/api/views/ez4e-fazm/rows.csv?accessType=DOWNLOAD'\n",
    "\n",
    "output_dir = '../data/raw/bus_breakdowns_delays/bus_breakdowns_delays.csv'\n",
    "\n",
    "urlretrieve(url, output_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.read_csv(output_dir, dtype={'Incident_Number': object}).to_parquet('../data/raw/bus_breakdowns_delays/bus_breakdowns_delays.parquet')\n",
    "\n",
    "#pd.read_csv(output_dir).dtypes\n",
    "\n",
    "#mv_collisions = pd.read_csv(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing bus_breakdowns parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\") # fix timestamps loaded by spark\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596085"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_breakdowns = spark.read.parquet('../data/raw/bus_breakdowns_delays/bus_breakdowns_delays.parquet')\n",
    "\n",
    "\n",
    "bus_breakdowns.limit(5)\n",
    "\n",
    "bus_breakdowns.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
